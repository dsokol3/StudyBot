# Server Configuration
server.port=8080

# Async request timeout (60 seconds for LLM responses)
spring.mvc.async.request-timeout=60000

# Database Configuration
spring.datasource.url=jdbc:postgresql://localhost:5433/chatbot
spring.datasource.username=chatbot_user
spring.datasource.password=chatbot_password
spring.datasource.driver-class-name=org.postgresql.Driver

# JPA/Hibernate Configuration
spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=true
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.properties.hibernate.format_sql=true

# Enable Postgres extensions (pgvector)
spring.jpa.properties.hibernate.jdbc.lob.non_contextual_creation=true
spring.sql.init.mode=always
spring.sql.init.platform=postgres
spring.sql.init.continue-on-error=true

# LLM Configuration (Groq API - RECOMMENDED)
# Groq provides fast cloud inference for text generation
llm.api.url=${LLM_API_URL:https://api.groq.com/openai/v1}
llm.api.key=${LLM_API_KEY:}
llm.model=${LLM_MODEL:llama-3.1-8b-instant}

# Logging
logging.level.com.chatbot=INFO
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} - %msg%n

# Thread Pool Configuration
spring.task.execution.pool.core-size=5
spring.task.execution.pool.max-size=10
spring.task.execution.pool.queue-capacity=100

# RAG Configuration
rag.enabled=true
rag.upload.storage-path=./uploads
rag.upload.max-file-size=52428800
rag.chunking.size=450
rag.chunking.overlap=50
rag.retrieval.top-k=5
rag.retrieval.max-distance=0.5
rag.retrieval.similarity-threshold=0.5

# Local Embedding Configuration (HuggingFace all-MiniLM-L6-v2)
# Embeddings are generated locally - no external API calls
rag.embedding.model-path=./models
rag.embedding.dimension=384
rag.embedding.cache-enabled=true

# Column definition used for embedding storage. Defaults to Postgres pgvector type.
rag.vector.columnDefinition=vector(384)

# File upload limits
spring.servlet.multipart.max-file-size=50MB
spring.servlet.multipart.max-request-size=50MB
