# Server Configuration
server.port=${PORT:8080}

# Default to 'dev' profile for local development
# On Render, set SPRING_PROFILES_ACTIVE=prod
spring.profiles.active=${SPRING_PROFILES_ACTIVE:dev}

# Async request timeout (60 seconds for LLM responses)
# spring.mvc.async.request-timeout=60000

# Database Configuration - profile-specific
# dev profile: H2 in-memory (application-dev.properties)
# prod profile: PostgreSQL (application-prod.properties)

# Connection pool settings for resilience (can be overridden by profile)
spring.datasource.hikari.connection-timeout=20000
spring.datasource.hikari.maximum-pool-size=${HIKARI_MAX_POOL_SIZE:5}
spring.datasource.hikari.minimum-idle=${HIKARI_MIN_IDLE:1}
spring.datasource.hikari.idle-timeout=300000
spring.datasource.hikari.max-lifetime=900000
spring.datasource.hikari.initialization-fail-timeout=60000
spring.datasource.hikari.validation-timeout=5000

# JPA/Hibernate Common Configuration
spring.jpa.properties.hibernate.format_sql=false
spring.jpa.defer-datasource-initialization=true
spring.jpa.open-in-view=false
# Do not use JDBC metadata to avoid early connection
spring.jpa.properties.hibernate.temp.use_jdbc_metadata_defaults=false

# Disable Flyway (not using it - schema managed by Hibernate)
spring.flyway.enabled=false

# SQL Initialization
spring.sql.init.mode=never
spring.sql.init.continue-on-error=true

# Spring Boot Actuator - Health Endpoints
# Disabled to prevent shutdown issues
# management.endpoints.web.exposure.include=health,info
# management.endpoints.web.base-path=/actuator
# management.endpoint.health.show-details=always
# Keep health probes disabled to prevent shutdown
# management.endpoint.health.probes.enabled=false
# management.health.livenessState.enabled=false
# management.health.readinessState.enabled=false
# management.endpoint.health.show-details=always
# management.endpoint.health.probes.enabled=false
# management.health.livenessState.enabled=false
# management.health.readinessState.enabled=false

# LLM Configuration (Groq API - RECOMMENDED)
# Groq provides fast cloud inference for text generation
llm.api.url=${LLM_API_URL:https://api.groq.com/openai/v1}
llm.api.key=${LLM_API_KEY:}
llm.model=${LLM_MODEL:llama-3.1-8b-instant}

# Logging
logging.level.com.chatbot=DEBUG
logging.level.org.springframework.web=DEBUG
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} - %msg%n

# Thread Pool Configuration
spring.task.execution.pool.core-size=5
spring.task.execution.pool.max-size=10
spring.task.execution.pool.queue-capacity=100

# RAG Configuration
rag.enabled=true
rag.upload.storage-path=./uploads
rag.upload.max-file-size=52428800
rag.chunking.size=450
rag.chunking.overlap=50
rag.retrieval.top-k=5
rag.retrieval.max-distance=0.5
rag.retrieval.similarity-threshold=0.5

# Google Gemini Embedding Configuration
# Use Google Gemini API for embeddings (text-embedding-004)
gemini.api.key=${GEMINI_API_KEY:}
gemini.api.max-retries=3
gemini.api.timeout-seconds=30
rag.embedding.dimension=768
rag.embedding.cache-enabled=true

# Column definition for embedding storage - profile-specific
# dev: TEXT (H2 doesn't support vector type)
# prod: vector(768) (PostgreSQL pgvector)

# File upload limits
spring.servlet.multipart.max-file-size=50MB
spring.servlet.multipart.max-request-size=50MB

# UV Markdown Extractor Configuration
# Enable/disable UV markdown extraction (falls back to Tika if disabled or unavailable)
uv.enabled=true
# Path to markitdown command (default: markitdown, assumes it's in PATH or will use 'uv tool run')
uv.command.path=markitdown
# Timeout for markitdown command execution in seconds
uv.command.timeout=60
# Whether to use 'uv tool run' prefix (set to true if markitdown is not globally installed)
uv.use.tool.run=true
